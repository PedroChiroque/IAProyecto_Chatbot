import streamlit as st
import os
from azure.storage.blob import BlobServiceClient
import time # Usado para la simulaci贸n
import openai # Importar la librer铆a de OpenAI

# --- Configuraci贸n de Streamlit y del Chatbot ---
st.set_page_config(page_title="Mi Chatbot de Documentos", page_icon="")

st.title(" Chatbot de Documentos")
st.write("隆Hola! Soy un chatbot entrenado con tus documentos. Hazme una pregunta.")
# 

# --- Configuraci贸n de Variables de Entorno y Conexi贸n a Azure y OpenAI ---
# En Streamlit Cloud, las variables de entorno se configuran como 'secrets'.
# Accedemos a ellas a trav茅s de st.secrets.
try:
    connection_string = st.secrets["AZURE_STORAGE_CONNECTION_STRING"]
    container_name = st.secrets["AZURE_CONTAINER_NAME"]
    openai_api_key = st.secrets["OPENAI_API_KEY"]
    
    # Conectar al servicio de Azure Blob Storage
    blob_service_client = BlobServiceClient.from_connection_string(connection_string)
    container_client = blob_service_client.get_container_client(container_name)
    
    # Inicializar el cliente de OpenAI
    client = openai.OpenAI(api_key=openai_api_key)

except KeyError as e:
    st.error(f"Error: La variable de entorno '{e.args[0]}' no est谩 configurada. Por favor, revisa tus 'secrets' en Streamlit Cloud.")
    st.stop()
except Exception as e:
    st.error(f"Error al conectar con un servicio: {e}")
    st.stop()

# --- L贸gica del Chatbot (Conexi贸n a OpenAI) ---
def get_chatbot_response(prompt, messages):
    """
    Esta funci贸n se conecta a la API de OpenAI para obtener una respuesta.
    El historial de mensajes se env铆a para mantener el contexto de la conversaci贸n.
    """
    
    # NOTA: Para usar el conocimiento de tus PDFs, necesitar铆as una
    # arquitectura de "Retrieval-Augmented Generation" (RAG). Esto
    # implica buscar la informaci贸n relevante en tus documentos ANTES
    # de llamar a la API de OpenAI y luego incluir esa informaci贸n en el prompt.
    # Esto requiere librer铆as como LangChain o LlamaIndex.
    # Este c贸digo es solo un ejemplo de conexi贸n directa con la API.
    
    response = client.chat.completions.create(
        model="gpt-5 mini", # Puedes usar otros modelos, como "gpt-4" gpt-3.5-turbo
        messages=[
            {"role": "system", "content": "Eres un asistente amigable y 煤til."},
            *messages # El asterisco expande el historial de mensajes
        ]
    )
    
    # Extraer la respuesta del asistente
    return response.choices[0].message.content

# --- Historial de Chat y UI de Streamlit ---
if "messages" not in st.session_state:
    # Inicializa el historial con un mensaje del asistente
    st.session_state.messages = [{"role": "assistant", "content": "隆Hola! 驴C贸mo puedo ayudarte con tus documentos?"}]

# Mostrar mensajes previos
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Manejar la entrada del usuario
if prompt := st.chat_input("驴Qu茅 deseas saber sobre los documentos?"):
    # Agregar el mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Obtener respuesta del chatbot
    with st.chat_message("assistant"):
        with st.spinner("Procesando tu solicitud..."):
            # Llama a la funci贸n de respuesta con el historial completo
            response = get_chatbot_response(prompt, st.session_state.messages)
            st.markdown(response)

    # Agregar la respuesta del asistente al historial
    st.session_state.messages.append({"role": "assistant", "content": response})
